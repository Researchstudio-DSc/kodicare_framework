{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "d = 4\n",
    "\n",
    "xb = np.array([\n",
    "    [0.1,0.2,0.3,0.4],\n",
    "    [0.1,0.2,0.9,1.0],\n",
    "    [0.5,0.6,0.7,0.8]\n",
    "], dtype=np.float32)\n",
    "\n",
    "index = faiss.IndexHNSWFlat(d, 2,faiss.METRIC_L2)   # build the index\n",
    "print(index.is_trained)\n",
    "index.add(xb)                  # add vectors to the index\n",
    "print(index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2]\n",
      " [1 2]\n",
      " [2 1]]\n",
      "[[0.         0.64000005]\n",
      " [0.         0.40000004]\n",
      " [0.         0.40000004]]\n"
     ]
    }
   ],
   "source": [
    "k = 2                          # we want to see 4 nearest neighbors\n",
    "D, I = index.search(xb, k) # sanity check\n",
    "print(I)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.9638632 , 0.96886396],\n",
       "       [0.9638632 , 1.        , 0.88938314],\n",
       "       [0.96886396, 0.88938314, 1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(xb, xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.18257418 0.36514837 0.5477226  0.73029673]\n",
      " [0.07332356 0.14664713 0.65991205 0.7332356 ]\n",
      " [0.37904903 0.45485887 0.5306686  0.60647845]]\n",
      "True\n",
      "hnsw_add_vertices: adding 3 elements on top of 0 (preset_levels=0)\n",
      "  max_level = 3\n",
      "Adding 2 elements at level 3\n",
      "Adding 0 elements at level 2\n",
      "Adding 0 elements at level 1\n",
      "Adding 1 elements at level 0\n",
      "3\n",
      "Done in 0.082 ms\n"
     ]
    }
   ],
   "source": [
    "faiss.normalize_L2(xb)\n",
    "\n",
    "print(xb)\n",
    "\n",
    "index = faiss.IndexHNSWFlat(d, 2,faiss.METRIC_INNER_PRODUCT)   # build the index\n",
    "index.verbose = True\n",
    "index.hnsw.efConstruction = 2\n",
    "index.hnsw.efSearch = 2\n",
    "print(index.is_trained)\n",
    "index.add(xb)                  # add vectors to the index\n",
    "print(index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2]\n",
      " [1 0]\n",
      " [2 0]]\n",
      "[[1.         0.96886396]\n",
      " [1.         0.96386325]\n",
      " [1.         0.96886396]]\n"
     ]
    }
   ],
   "source": [
    "k = 2                          # we want to see 4 nearest neighbors\n",
    "D, I = index.search(xb, k) # sanity check\n",
    "print(I)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.96386325, 0.96886396],\n",
       "       [0.96386325, 1.0000001 , 0.8893832 ],\n",
       "       [0.96886396, 0.8893832 , 1.0000001 ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(xb, xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hnsw_add_vertices: adding 3 elements on top of 0 (preset_levels=0)\n",
      "  max_level = 3\n",
      "Adding 2 elements at level 3\n",
      "Adding 0 elements at level 2\n",
      "Adding 0 elements at level 1\n",
      "Adding 1 elements at level 0\n",
      "Done in 0.547 ms\n"
     ]
    }
   ],
   "source": [
    "index = faiss.IndexHNSWFlat(d, 2,faiss.METRIC_INNER_PRODUCT)   # build the index\n",
    "index.verbose = True\n",
    "index.hnsw.efConstruction = 2\n",
    "index.hnsw.efSearch = 2\n",
    "\n",
    "ids = np.arange(xb.shape[0]) + 10\n",
    "\n",
    "index2 = faiss.IndexIDMap(index)\n",
    "index2.add_with_ids(xb, ids) # works, the vectors are stored in the underlying index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10 12]\n",
      " [11 10]\n",
      " [12 10]]\n",
      "[[1.         0.96886396]\n",
      " [1.         0.96386325]\n",
      " [1.         0.96886396]]\n"
     ]
    }
   ],
   "source": [
    "k = 2                          # we want to see 4 nearest neighbors\n",
    "D, I = index2.search(xb, k) # sanity check\n",
    "print(I)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class BaseNNIndexer():\n",
    "    '''\n",
    "    Base class for our nearest neighbor indexing operations, atm we mainly abstrcat faiss, but it should allow us to swap in other libs fairly easy\n",
    "    '''\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(BaseNNIndexer, self).__init__()\n",
    "\n",
    "        self.token_dim = config[\"token_dim\"]\n",
    "        self.use_gpu = config[\"faiss_use_gpu\"]\n",
    "        self.use_fp16 = config[\"token_dtype\"] == \"float16\"\n",
    "\n",
    "    def prepare(self, data_chunks:List[np.ndarray], subsample=-1):\n",
    "        '''\n",
    "        Train an index with (all) or only some vectors, if subsample is set to a value between 0 and 1\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def index(self, ids:List[np.ndarray], data_chunks:List[np.ndarray]):\n",
    "        '''\n",
    "        ids: need to be int64\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def search(self, query_vec:np.ndarray, top_n:int):\n",
    "        '''\n",
    "        query_vec: can be 2d (batch search) or 1d (single search) \n",
    "        '''\n",
    "        pass\n",
    "\n",
    "\n",
    "class FaissBaseIndexer(BaseNNIndexer):\n",
    "    '''\n",
    "    Shared faiss code\n",
    "    '''\n",
    "\n",
    "    def __init__(self,config):\n",
    "        super(FaissBaseIndexer, self).__init__(config)\n",
    "        self.faiss_index:faiss.Index = None # needs to be initialized by the actual faiss classes\n",
    "\n",
    "    def index(self, ids:List[np.ndarray], data_chunks:List[np.ndarray]):\n",
    "        # single add needed for multi-gpu index (sharded), and hnsw so just do it for all (might be a memory problem at some point, but we can come back to that)\n",
    "        i = np.concatenate(ids).astype(np.int64)\n",
    "        c = np.concatenate(data_chunks).astype(np.float32)\n",
    "        self.faiss_index.add_with_ids(c,i)\n",
    "\n",
    "    def search(self, query_vec:np.ndarray, top_n:int):\n",
    "        # even a single search must be 1xn dims\n",
    "        if len(query_vec.shape) == 1:\n",
    "            query_vec = query_vec[np.newaxis,:]\n",
    "            \n",
    "        res_scores, indices = self.faiss_index.search(query_vec.astype(np.float32),top_n)\n",
    "\n",
    "        return res_scores, indices\n",
    "\n",
    "    def save(self, path:str):\n",
    "        if self.use_gpu:\n",
    "            idx = faiss.index_gpu_to_cpu(self.faiss_index)\n",
    "        else:\n",
    "            idx = self.faiss_index\n",
    "        faiss.write_index(idx, path)\n",
    "    \n",
    "    def load(self, path:str,config_overwrites=None):\n",
    "        self.faiss_index = faiss.read_index(path)\n",
    "\n",
    "\n",
    "class FaissIdIndexer(FaissBaseIndexer):\n",
    "    '''\n",
    "    Simple brute force nearest neighbor faiss index with id mappings, with potential gpu usage, support for fp16\n",
    "    -> if faiss_use_gpu=True use all availbale GPUs in a sharded index \n",
    "    '''\n",
    "\n",
    "    def __init__(self,config):\n",
    "        super(FaissIdIndexer, self).__init__(config)\n",
    "\n",
    "        if self.use_gpu:\n",
    "\n",
    "            cpu_index = faiss.IndexIDMap(faiss.IndexFlatIP(config[\"token_dim\"]))\n",
    "                        \n",
    "            co = faiss.GpuMultipleClonerOptions()\n",
    "            co.shard = True\n",
    "            co.useFloat16 = self.use_fp16\n",
    "\n",
    "            self.faiss_index = faiss.index_cpu_to_all_gpus(cpu_index,co)\n",
    "\n",
    "        else:\n",
    "            if self.use_fp16:\n",
    "                self.faiss_index = faiss.IndexIDMap(faiss.IndexScalarQuantizer(config[\"token_dim\"],faiss.ScalarQuantizer.QT_fp16,faiss.METRIC_INNER_PRODUCT))\n",
    "            else:\n",
    "                self.faiss_index = faiss.IndexIDMap(faiss.IndexFlatIP(config[\"token_dim\"]))\n",
    "\n",
    "\n",
    "class FaissHNSWIndexer(FaissBaseIndexer):\n",
    "    '''\n",
    "    HNSW - graph based - index, only supports CPU - but gets very low query latency \n",
    "    '''\n",
    "\n",
    "    def __init__(self,config):\n",
    "        super(FaissHNSWIndexer, self).__init__(config)\n",
    "\n",
    "        self.use_gpu = False # HNSW does not support GPUs\n",
    "\n",
    "        if self.use_fp16:\n",
    "            self.faiss_index = faiss.IndexHNSWSQ(config[\"token_dim\"],faiss.ScalarQuantizer.QT_fp16,\n",
    "                                                config[\"faiss_hnsw_graph_neighbors\"],faiss.METRIC_INNER_PRODUCT)\n",
    "\n",
    "        else:\n",
    "            self.faiss_index = faiss.IndexHNSWFlat(config[\"token_dim\"],config[\"faiss_hnsw_graph_neighbors\"],faiss.METRIC_INNER_PRODUCT)\n",
    "        \n",
    "        self.faiss_index.verbose = True\n",
    "        self.faiss_index.hnsw.efConstruction = config[\"faiss_hnsw_efConstruction\"]\n",
    "        self.faiss_index.hnsw.efSearch = config[\"faiss_hnsw_efSearch\"]\n",
    "\n",
    "        self.faiss_index = faiss.IndexIDMap(self.faiss_index)\n",
    "\n",
    "    def prepare(self, data_chunks:List[np.ndarray], subsample=-1):\n",
    "        if self.use_fp16:\n",
    "            # training for the scalar quantizer, according to: https://github.com/facebookresearch/faiss/blob/master/benchs/bench_hnsw.py\n",
    "            self.faiss_index.train(np.concatenate(data_chunks).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hnsw_add_vertices: adding 3 elements on top of 0 (preset_levels=0)\n",
      "  max_level = 3\n",
      "Adding 2 elements at level 3\n",
      "Adding 0 elements at level 2\n",
      "Adding 0 elements at level 1\n",
      "Adding 1 elements at level 0\n",
      "Done in 0.388 ms\n",
      "hnsw_add_vertices: adding 3 elements on top of 3 (preset_levels=0)\n",
      "  max_level = 0\n",
      "Adding 3 elements at level 0\n",
      "Done in 0.062 ms\n"
     ]
    }
   ],
   "source": [
    "index_config = {\n",
    "    \"token_dim\": 4,\n",
    "    \"faiss_hnsw_graph_neighbors\": 2,\n",
    "    \"faiss_hnsw_efConstruction\": 2,\n",
    "    \"faiss_hnsw_efSearch\": 2,\n",
    "    \"faiss_use_gpu\": False,\n",
    "    \"token_dtype\": \"float32\"\n",
    "}\n",
    "\n",
    "indexer = FaissHNSWIndexer(index_config)\n",
    "\n",
    "indexer.index(ids=[ids], data_chunks=[xb])\n",
    "indexer.index(ids=[ids+10], data_chunks=[xb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.0000000e+00,  1.0000000e+00,  9.6886396e-01,  9.6386325e-01,\n",
       "         -3.4028235e+38, -3.4028235e+38],\n",
       "        [ 1.0000000e+00,  1.0000000e+00,  9.6386325e-01,  8.8938320e-01,\n",
       "         -3.4028235e+38, -3.4028235e+38],\n",
       "        [ 1.0000000e+00,  1.0000000e+00,  9.6886396e-01,  9.6886396e-01,\n",
       "          8.8938320e-01,  8.8938320e-01]], dtype=float32),\n",
       " array([[10, 20, 12, 21, -1, -1],\n",
       "        [11, 21, 10, 12, -1, -1],\n",
       "        [22, 12, 20, 10, 11, 21]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer.search(xb, top_n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kodicare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

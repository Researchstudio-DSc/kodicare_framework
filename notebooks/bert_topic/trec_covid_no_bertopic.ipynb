{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tfink/miniconda3/envs/bertopic/lib/python3.9/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/tfink/miniconda3/envs/bertopic/lib/python3.9/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/tfink/miniconda3/envs/bertopic/lib/python3.9/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/tfink/miniconda3/envs/bertopic/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/tfink/miniconda3/envs/bertopic/lib/python3.9/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import umap\n",
    "import hdbscan\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans, BisectingKMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "random_state = 42\n",
    "#random_state = 420\n",
    "random.seed(random_state)\n",
    "\n",
    "f_tokenized_path = \"/home/tfink/data/kodicare/trec-covid/dtc_evolving_bert/0.csv\"\n",
    "f_tokenized_other_path = \"/home/tfink/data/kodicare/trec-covid/dtc_evolving_bert/11.csv\"\n",
    "f_tokenized_contrast_path = \"/home/tfink/projects/rsa/kodicare/kodicare_framework/data/trec_covid_topic_modelling/abcnews-date-text.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cleaned(path):\n",
    "    with open(path, \"r\") as fp:\n",
    "        reader = csv.reader(fp, delimiter=\",\", quotechar='\"')\n",
    "        passages = []\n",
    "        passage_uids = []\n",
    "        for line in tqdm(reader):\n",
    "            cord_uid, passage_text_cleaned = line\n",
    "            passages.append(passage_text_cleaned)\n",
    "            passage_uids.append(cord_uid)\n",
    "        return passages, passage_uids\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1115954it [00:08, 125403.63it/s]\n"
     ]
    }
   ],
   "source": [
    "passages, passage_uids = read_cleaned(f_tokenized_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('in conjunction with the virus this organism produced a vigorous leukocytic reaction.',\n",
       " '04ceiyko')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages[50], passage_uids[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3125/3125 [03:03<00:00, 17.03it/s]\n"
     ]
    }
   ],
   "source": [
    "embedding_model = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "model = SentenceTransformer(embedding_model)\n",
    "passages_encoded = model.encode(passages[:100000], show_progress_bar=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP(angular_rp_forest=True, metric='cosine', min_dist=0.0, n_components=5, random_state=42, verbose=True)\n",
      "Wed Aug  2 17:32:39 2023 Construct fuzzy simplicial set\n",
      "Wed Aug  2 17:32:39 2023 Finding Nearest Neighbors\n",
      "Wed Aug  2 17:32:39 2023 Building RP forest with 21 trees\n",
      "Wed Aug  2 17:32:41 2023 NN descent for 17 iterations\n",
      "\t 1  /  17\n",
      "\t 2  /  17\n",
      "\t 3  /  17\n",
      "\t 4  /  17\n",
      "\t 5  /  17\n",
      "\t 6  /  17\n",
      "\t 7  /  17\n",
      "\tStopping threshold met -- exiting after 7 iterations\n",
      "Wed Aug  2 17:32:44 2023 Finished Nearest Neighbor Search\n",
      "Wed Aug  2 17:32:44 2023 Construct embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed: 100%| ██████████ 200/200 [00:32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug  2 17:33:25 2023 Finished embedding\n"
     ]
    }
   ],
   "source": [
    "# dimensionality reduction\n",
    "umap_model = umap.UMAP(n_neighbors=15, \n",
    "                       n_components=5, \n",
    "                       min_dist=0.0, \n",
    "                       metric='cosine', \n",
    "                       random_state=random_state, \n",
    "                       verbose=True)\n",
    "embedding = umap_model.fit_transform(passages_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = int(np.sqrt(len(embedding)))\n",
    "n_clusters = 350\n",
    "\n",
    "clustering_model = BisectingKMeans(n_clusters=n_clusters, \n",
    "                       n_init=1,\n",
    "                       bisecting_strategy='largest_cluster',\n",
    "                       random_state=random_state)\n",
    "topics = clustering_model.fit_predict(embedding)\n",
    "\n",
    "# clustering_model = GaussianMixture(n_components=n_clusters, \n",
    "#                        n_init=1,\n",
    "#                        init_params='k-means++',\n",
    "#                        covariance_type='diag',\n",
    "#                        reg_covar=1e-3,\n",
    "#                        random_state=random_state)\n",
    "# topics = clustering_model.fit_predict(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in conjunction with the virus this organism produced a vigorous leukocytic reaction.']\n",
      "[313]\n",
      "[0.00530461]\n",
      "[0.00271237]\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "print(passages[50:51])\n",
    "print(clustering_model.predict(embedding[50:51]))\n",
    "t = clustering_model.transform(embedding[50:51])\n",
    "ts = softmax(np.exp(-t), axis=-1)\n",
    "print(ts[:,np.argmax(ts)])\n",
    "print(ts[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3125/3125 [03:03<00:00, 16.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug  2 17:17:40 2023 Worst tree score: 0.71285000\n",
      "Wed Aug  2 17:17:40 2023 Mean tree score: 0.71946571\n",
      "Wed Aug  2 17:17:40 2023 Best tree score: 0.72525000\n",
      "Wed Aug  2 17:17:42 2023 Forward diversification reduced edges from 1500000 to 610481\n",
      "Wed Aug  2 17:17:46 2023 Reverse diversification reduced edges from 610481 to 610481\n",
      "Wed Aug  2 17:17:48 2023 Degree pruning reduced edges from 774636 to 770039\n",
      "Wed Aug  2 17:17:48 2023 Resorting data and graph based on tree order\n",
      "Wed Aug  2 17:17:48 2023 Building and compiling search function\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed: 100%| ██████████ 30/30 [00:03]\n"
     ]
    }
   ],
   "source": [
    "other_p = model.encode(passages[100000:200000], show_progress_bar=True, batch_size=32)\n",
    "other_p = umap_model.transform(other_p)\n",
    "other_topics = clustering_model.predict(other_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_proportions(topics):\n",
    "    # first calculate base topic counts and proportions\n",
    "    outlier_count = 0\n",
    "    topic_counts = {topic:0 for topic in range(n_clusters)}\n",
    "    topic_proportions = {}\n",
    "    non_outlier_docs = 0\n",
    "    for idx, topic in enumerate(topics):\n",
    "        if topic == -1:\n",
    "            outlier_count += 1\n",
    "            continue\n",
    "        non_outlier_docs += 1\n",
    "        topic_counts[topic] += 1\n",
    "    for topic in range(n_clusters):\n",
    "        topic_proportions[topic] = topic_counts[topic] / non_outlier_docs\n",
    "    outlier_proportion = outlier_count / len(topics)\n",
    "    return topic_proportions, outlier_proportion\n",
    "\n",
    "\n",
    "def get_intersection(topic_proportions_a, topic_proportions_b):\n",
    "    total = 0\n",
    "    for topic in range(n_clusters):\n",
    "        total += min(topic_proportions_a[topic], topic_proportions_b[topic])\n",
    "    return total\n",
    "\n",
    "\n",
    "def calculate_topic_intersection(base_topics, other_topics):\n",
    "    base_topic_proportions, base_outlier_proportion = get_topic_proportions(base_topics)\n",
    "    other_topic_proportions, other_outlier_proportion = get_topic_proportions(other_topics)\n",
    "\n",
    "    # calc\n",
    "    intersection = get_intersection(base_topic_proportions, other_topic_proportions)\n",
    "    print(f\"base_outliers: {base_outlier_proportion:.2%}, other_outliers: {other_outlier_proportion:.2%}, intersection: {intersection:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_outliers: 0.00%, other_outliers: 0.00%, intersection: 72.60%\n"
     ]
    }
   ],
   "source": [
    "base_topic_proportions, base_outlier_proportion = get_topic_proportions(topics)\n",
    "other_topic_proportions, other_outlier_proportion = get_topic_proportions(other_topics)\n",
    "\n",
    "# calc\n",
    "intersection = get_intersection(base_topic_proportions, other_topic_proportions)\n",
    "print(f\"base_outliers: {base_outlier_proportion:.2%}, other_outliers: {other_outlier_proportion:.2%}, intersection: {intersection:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Topics\": [\"outliers\"] + [str(topic) for topic in range(n_clusters)],\n",
    "    'Base': [base_outlier_proportion]+[base_topic_proportions[topic] for topic in range(n_clusters)],\n",
    "    'Other': [other_outlier_proportion]+[other_topic_proportions[topic] for topic in range(n_clusters)],\n",
    "})\n",
    "\n",
    "fig = px.bar(\n",
    "    data_frame = df,\n",
    "    x = \"Topics\",\n",
    "    y = [\"Base\",\"Other\"],\n",
    "    opacity = 0.9,\n",
    "    orientation = \"v\",\n",
    "    barmode = 'group',\n",
    "    title='Topic Proportions',\n",
    "    color_discrete_sequence=px.colors.qualitative.D3\n",
    "    #color_discrete_sequence=px.colors.sequential.Inferno_r\n",
    ")\n",
    "fig.update_yaxes(range=[0.0, 0.035])\n",
    "fig.write_html(\"trec_covid_small.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1244184it [00:00, 1279913.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aba decides against community broadcasting licence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open(f_tokenized_contrast_path, \"r\") as fp:\n",
    "    reader = csv.reader(fp, delimiter=\",\", quotechar='\"')\n",
    "    passages_contrast = []\n",
    "    passage_uids = []\n",
    "    # skip first line\n",
    "    reader.__next__()\n",
    "    for line in tqdm(reader):\n",
    "        cord_uid, passage_text_cleaned = line\n",
    "        passages_contrast.append(passage_text_cleaned)\n",
    "        passage_uids.append(cord_uid)\n",
    "print(passages_contrast[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3125/3125 [00:24<00:00, 127.77it/s]\n",
      "Epochs completed: 100%| ██████████ 30/30 [00:05]\n",
      "2023-07-18 15:31:03,554 - BERTopic - Reduced dimensionality\n",
      "2023-07-18 15:31:03,631 - BERTopic - Predicted clusters\n"
     ]
    }
   ],
   "source": [
    "contrast_topics, _ = topic_model.transform(passages_contrast[:100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_outliers: 0.00%, other_outliers: 0.00%, intersection: 57.84%, MAE: 0.0024, AE: 0.8432\n"
     ]
    }
   ],
   "source": [
    "contrast_topic_proportions, contrast_outlier_proportion = get_topic_proportions(contrast_topics)\n",
    "\n",
    "# calc\n",
    "intersection = get_intersection(base_topic_proportions, contrast_topic_proportions)\n",
    "mae = get_MAE(base_topic_proportions, contrast_topic_proportions)\n",
    "ae = get_absolute_error(base_topic_proportions, contrast_topic_proportions)\n",
    "print(f\"base_outliers: {base_outlier_proportion:.2%}, other_outliers: {other_outlier_proportion:.2%}, intersection: {intersection:.2%}, MAE: {mae:.4f}, AE: {ae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Topics\": [\"outliers\"] + [str(topic) for topic in range(len(topic2desc))],\n",
    "    \"Topics_Names\": [\"outliers\"] + [topic2desc[topic] for topic in range(len(topic2desc))],\n",
    "    'Base': [base_outlier_proportion]+[base_topic_proportions[topic] for topic in range(len(topic2desc))],\n",
    "    'Other': [contrast_outlier_proportion]+[contrast_topic_proportions[topic] for topic in range(len(topic2desc))],\n",
    "})\n",
    "\n",
    "fig = px.bar(\n",
    "    data_frame = df,\n",
    "    x = \"Topics\",\n",
    "    y = [\"Base\",\"Other\"],\n",
    "    opacity = 0.9,\n",
    "    orientation = \"v\",\n",
    "    barmode = 'group',\n",
    "    title='Topic Proportions',\n",
    "    hover_data=[\"Topics_Names\"],\n",
    "    color_discrete_sequence=px.colors.qualitative.D3\n",
    "    #color_discrete_sequence=px.colors.sequential.Inferno_r\n",
    ")\n",
    "fig.update_yaxes(range=[0.0, 0.035])\n",
    "fig.write_html(\"trec_covid_small_contrast.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertopic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

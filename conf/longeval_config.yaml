config:
  root_dir: ??? # the root directory of the whole data set base
  lang: 'en'

test_collection:
  language: en
  documents_dir: qwant/2022/merged_collection/French/Documents/json/ # json directory of documents to index
  queries_path: qwant/2022/merged_collection/queries_merged.trec # trec full path of queries
  qrels_path: qwant/2022/merged_collection/qrels_merged.txt # txt full path of qrels
  runs_output_dir: qwant/2022/merged_collection/runs

index:
  index_path: qwant/2022/merged_collection/French/pyterrier_index # directory to store the index in

dtc: # dynamic test collection information
  evaluation_splits_dir: qwant/2022/evee #the output directory of retrieval results
  docno_date_path: longeval_docno_sorted_filtered.csv
  n_evee: 41 # number of EE to create
  evee_overlap: 10 # the percentage of overlap between EEs
  evee_info_path: evee_docnos_16_41_10.pkl
  collectors_dirs:
    - qwant/2022/longeval-train-v2/publish/French/Documents/Json
    - qwant/2022/longeval-test-collection/test-collection/A-Short-July/French/Documents/Json
    - qwant/2022/longeval-test-collection/test-collection/B-Long-September/French/Documents/Json
  merged_collectors_dir: merged_collectors
  doc_ids__time__infos:
    - qwant/2022/evee/urls-with-times-06-train.txt
    - qwant/2022/evee/urls-with-times-07.txt
    - qwant/2022/evee/urls-with-times-09.txt
  doc_id_date_info_path: qwant/2022/evee/longeval_docno_sorted.csv
  dtc_evolving_content_dir: evee_docs_contents
  index:
    index_path: pyterrier_index # directory to store the index in
  queries_merged: queries_merged.trec
  qrels_merged: qrels_merged.txt

  evaluation:
    evaluation_perquery_output_path: evaluation_per_query # dir will contain tsv files of the retrieval results per query
    evaluation_mean_output_path: evaluation_mean #dir will contain tsv files of the average retrieval results
    rd_absolute_perquery_path: rd_absolute_perquery_path #dir contain the absolute rd per query
    rd_absolute_mean_path: rd_absolute_mean_path #dir contain the absolute rd of the mean
    rd_relative_perquery_path: rd_relative_perquery_path #dir contain the relative rd per query
    rd_relative_mean_path: rd_relative_mean_path #dir contain the relative rd of the mean

evaluation:
  evaluation_perquery_output_path: qwant/2022/merged_collection/French/evaluation_perquery.csv # tsv file path for evaluation for each query
  evaluation_mean_output_path: qwant/2022/merged_collection/French/evaluation_mean.csv #tsv path of evaluation for the mean of the queries

retrieval_models:
  - 0:
      run_name: tfidf
      model: TF_IDF
  - 1:
      run_name: bm25
      model: BM25
  - 2:
      run_name: pl2
      model: PL2
  - 3:
      run_name: dlm
      model: DirichletLM
  - 4:
      run_name: dlh
      model: DLH
  - 5:
      run_name: dph
      model: DPH
  - 6:
      run_name: tfidf_qe
      model: TF_IDF
      controls:
        qe: on
        qemodel: Bo1
  - 7:
      run_name: bm25_qe
      model: BM25
      controls:
        qe: on
        qemodel: Bo1
  - 8:
      run_name: pl2_qe
      model: PL2
      controls:
        qe: on
        qemodel: Bo1
  - 9:
      run_name: dlm_qe
      model: DirichletLM
      controls:
        qe: on
        qemodel: Bo1
  - 10:
      run_name: dlh_qe
      model: DLH
      controls:
        qe: on
        qemodel: Bo1
  - 11:
      run_name: dph_qe
      model: DPH
      controls:
        qe: on
        qemodel: Bo1

evaluation_metrics:
  - map
  - bpref
  - ndcg
  - Rprec
  - recip_rank
  - ndcg_cut_10
  - P_10